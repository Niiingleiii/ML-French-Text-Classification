# -*- coding: utf-8 -*-
"""Data Augmentation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TjT7LuDbh6_xMIiHDrqAh72oIcOXivI4
"""

import pandas as pd
import random

# Load the provided training data
train_data_path = 'https://raw.githubusercontent.com/Niiingleiii/ML-data/main/training_data.csv'
train_df = pd.read_csv(train_data_path)

# Function to generate variations of a given sentence
def generate_variations(sentence, num_variations=10):
    words = sentence.split()
    variations = []

    for _ in range(num_variations):
        new_words = words[:]
        idx_to_replace = random.sample(range(len(words)), k=min(2, len(words)))  # Change up to 2 words
        for idx in idx_to_replace:
            new_words[idx] = random.choice(words)
        variations.append(' '.join(new_words))

    return variations

# Generate additional sentences
additional_sentences = []
for idx, row in train_df.iterrows():
    sentence = row['sentence']
    difficulty = row['difficulty']
    variations = generate_variations(sentence, num_variations=10)  # Generate 10 variations per sentence
    for variation in variations:
        additional_sentences.append({'sentence': variation, 'difficulty': difficulty})

# Convert additional sentences to DataFrame
additional_df = pd.DataFrame(additional_sentences)

# Combine the original and additional data
augmented_df = pd.concat([train_df, additional_df], ignore_index=True)

# Shuffle the combined data
augmented_df = augmented_df.sample(frac=1).reset_index(drop=True)

# Ensure we have at least 7000 data entries
if len(augmented_df) > 7000:
    augmented_df = augmented_df.sample(n=7000, random_state=42).reset_index(drop=True)

# Save the augmented data to a new CSV file
augmented_data_path = '/content/augmented_training_data_7000_v3.csv'
augmented_df.to_csv(augmented_data_path, index=False)

