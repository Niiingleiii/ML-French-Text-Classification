# -*- coding: utf-8 -*-
"""“Best Model.ipynb”的副本

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zZSawNWfCyx2fr1dxFIXQ9SStK91kdAL
"""

!pip uninstall accelerate -y

!pip install transformers datasets evaluate accelerate -U

import accelerate
print(accelerate.__version__)

import os
import pandas as pd
import torch
from sklearn.model_selection import train_test_split
from transformers import CamembertTokenizer, CamembertForSequenceClassification
from transformers import Trainer, TrainingArguments
from datasets import Dataset, Features, ClassLabel, Value
import evaluate
import numpy as np

# Assuming the uploaded files are named 'training_data.csv', 'augmented_training_data_7000_v3.csv', and 'unlabelled_test_data.csv'
train_data_path = 'https://raw.githubusercontent.com/Niiingleiii/ML-data/main/training_data.csv'
aug_data_path = 'https://raw.githubusercontent.com/emilysr2/Data-Science-and-Machine-Learning/main/augmented_training_data_7000_v3%20(1).csv'
test_data_path = 'https://raw.githubusercontent.com/Niiingleiii/ML-data/main/unlabelled_test_data.csv'

# Load dataset
dataset = pd.read_csv(train_data_path)
aug_dataset = pd.read_csv(aug_data_path)
dataset = pd.concat([dataset, aug_dataset], ignore_index=True)
dataset['difficulty'] = dataset['difficulty'].astype('category')
class_names = dataset['difficulty'].cat.categories.tolist()

print(f'Number of datapoints: {len(dataset)}')
print(f'Datatable:\n {dataset.head(4)}')
print(f'Datatable columns {dataset.columns}')

train_set, validation_set = train_test_split(dataset, test_size=0.1, random_state=42)

# Print the size of each set
print(f'Number of training datapoints: {len(train_set)}')
print(f'Number of validation datapoints: {len(validation_set)}')

# Optionally, print some samples from each set
print(f'Training datatable sample:\n {train_set.head(3)}')
print(f'Validation datatable sample:\n {validation_set.head(3)}')

# Number of labels
num_labels = train_set['difficulty'].nunique()
print(f'Number of labels: {num_labels}')

# Ensure data types are supported
train_set['difficulty'] = train_set['difficulty'].cat.codes
validation_set['difficulty'] = validation_set['difficulty'].cat.codes

# Fill any missing values
train_set = train_set.fillna('')
validation_set = validation_set.fillna('')

# Rename columns to match expected feature names
train_set = train_set.rename(columns={'sentence': 'text', 'difficulty': 'labels'})
validation_set = validation_set.rename(columns={'sentence': 'text', 'difficulty': 'labels'})

# Select only the columns needed for the Dataset
train_set = train_set[['text', 'labels']]
validation_set = validation_set[['text', 'labels']]

# Define feature types explicitly
features = Features({
    'text': Value('string'),
    'labels': ClassLabel(num_classes=num_labels)
})

# Load tokenizer and model
tokenizer = CamembertTokenizer.from_pretrained('camembert-base')

# Freeze all layers except the last two transformer layers and the classification head
def freeze_layers(model):
    for param in model.roberta.parameters():
        param.requires_grad = False

    # Access the last layer of the encoder
    last_layer = model.roberta.encoder.layer[-1:]
    # Enable gradient computation for the parameters in the last layer
    for param in last_layer.parameters():
        param.requires_grad = True

    for param in model.classifier.parameters():
        param.requires_grad = True

# Preprocess data
def preprocess_function(examples):
    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=512)

# Create Hugging Face Datasets
train_dataset = Dataset.from_pandas(train_set, features=features, preserve_index=False)
val_dataset = Dataset.from_pandas(validation_set, features=features, preserve_index=False)

train_dataset = train_dataset.map(preprocess_function, batched=True)
val_dataset = val_dataset.map(preprocess_function, batched=True)

# Evaluation
accuracy_metric = evaluate.load('accuracy')
precision_metric = evaluate.load('precision')
recall_metric = evaluate.load('recall')
f1_metric = evaluate.load('f1')

def compute_metrics(p):
    preds = p.predictions.argmax(-1)
    labels = p.label_ids
    accuracy = accuracy_metric.compute(predictions=preds, references=labels)
    precision = precision_metric.compute(predictions=preds, references=labels, average='weighted')
    recall = recall_metric.compute(predictions=preds, references=labels, average='weighted')
    f1 = f1_metric.compute(predictions=preds, references=labels, average='weighted')
    return {
        'eval_accuracy': accuracy['accuracy'],
        'eval_precision': precision['precision'],
        'eval_recall': recall['recall'],
        'eval_f1': f1['f1']
    }

# Training configurations
training_configs = [
    {'seed': 42, 'learning_rate': 10e-5}
]

models = []
trainers = []

from transformers import CamembertForSequenceClassification, Trainer, TrainingArguments

import torch

# Check if CUDA is available
if torch.cuda.is_available():
    # Get the name of the GPU
    gpu_name = torch.cuda.get_device_name(0)
    # Get the GPU memory usage
    gpu_memory_allocated = torch.cuda.memory_allocated(0)
    gpu_memory_reserved = torch.cuda.memory_reserved(0)

    print(f"GPU Name: {gpu_name}")
    print(f"Memory Allocated: {gpu_memory_allocated / 1024 ** 3:.2f} GB")
    print(f"Memory Reserved: {gpu_memory_reserved / 1024 ** 3:.2f} GB")
else:
    print("No GPU available")

# Train the model
for config in training_configs:
    model = CamembertForSequenceClassification.from_pretrained('camembert-base', num_labels=num_labels)
    freeze_layers(model)

    training_args = TrainingArguments(
        output_dir=f'./results_seed_{config["seed"]}',
        eval_strategy='epoch',  # Updated to use 'eval_strategy'
        learning_rate=config['learning_rate'],
        per_device_train_batch_size=32,
        per_device_eval_batch_size=32,
        num_train_epochs=6,
        weight_decay=0.01,
        logging_dir=f'./logs_seed_{config["seed"]}',
        logging_steps=15,
        seed=config['seed']
    )
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        compute_metrics=compute_metrics
    )

    trainer.train()
    trainers.append(trainer)
    models.append(model)

    # Evaluate the model
    metrics = trainer.evaluate()
    print(f"Metrics for seed {config['seed']}:")
    print(f"Accuracy: {metrics['eval_accuracy']}")
    print(f"Precision: {metrics['eval_precision']}")
    print(f"Recall: {metrics['eval_recall']}")
    print(f"F1 Score: {metrics['eval_f1']}")

# Evaluate the models and make predictions
test_data = pd.read_csv(test_data_path)
test_data = test_data.rename(columns={'sentence': 'text'})
id = test_data[['id']]
test_data = test_data[['text']]
test_dataset = Dataset.from_pandas(test_data, preserve_index=False)
test_dataset = test_dataset.map(preprocess_function, batched=True)
test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])

# Collect predictions from each model
all_predictions = []

for trainer in trainers:
    predictions = trainer.predict(test_dataset)
    all_predictions.append(predictions.predictions)

# Average the predictions to get the final prediction
average_predictions = np.mean(np.stack(all_predictions), axis=0)
final_preds = np.argmax(average_predictions, axis=1)

# Map the predictions to the original labels
pred_labels = [class_names[pred] for pred in final_preds]

# Save the predictions to a submission file
submission = pd.DataFrame({'id': id['id'].values.tolist(), 'difficulty': pred_labels})
submission.to_csv('/content/submission_ensemble.csv', index=False)

print("Ensemble predictions saved to submission_ensemble.csv")

# Code to download the file in Google Colab
from google.colab import files
files.download('/content/submission_ensemble.csv')